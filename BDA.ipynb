{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyEMD import EMD, Visualisation\n",
    "import scipy\n",
    "import math\n",
    "import scipy.io\n",
    "import scipy.linalg\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(V):\n",
    "    return ( V - min(V.flatten()) ) / ( max(V.flatten()) - min(V.flatten()) )\n",
    "\n",
    "\n",
    "def sliding_window(T, T_org, seq_len, label_seq_len):\n",
    "\n",
    "    # seq_len is equal to window_size\n",
    "    # T (np.array) has dim: population, seq_len (window length)\n",
    "    TT = T.reshape(-1, 1)\n",
    "    K = TT.shape[0] - seq_len - label_seq_len + 1  # Li, et al., 2021, TRJ part C, pp. 8\n",
    "    \n",
    "    TT_org = T_org.reshape(-1, 1)\n",
    "\n",
    "    # TT has dim: n, 1\n",
    "    # assemble the data into 2D\n",
    "    x_set = np.vstack(TT[i : K+i, 0] for i in range(seq_len)).T\n",
    "    y_set = np.vstack(TT_org[i+seq_len : K+seq_len+i, 0] for i in range(label_seq_len)).T\n",
    "    \n",
    "    assert x_set.shape[0] == y_set.shape[0]\n",
    "\n",
    "    # return size: n_samp, seq_len\n",
    "    return x_set, y_set\n",
    "\n",
    "\n",
    "def var_name(var, all_var=locals()):\n",
    "    # get the name of the variable\n",
    "    return [var_name for var_name in all_var if all_var[var_name] is var][0]\n",
    "\n",
    "\n",
    "def np2csv(A):\n",
    "    # store numpy to local csv file\n",
    "    if type(A) == torch.Tensor:\n",
    "        np.savetxt('./outputs/BDA/'+var_name(A)+'.csv', A.detach().numpy(), delimiter=',')\n",
    "    elif type(A) == np.ndarray:\n",
    "        np.savetxt('./outputs/BDA/'+var_name(A)+'.csv', A, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BDA Part\n",
    "## 1.a. Define BDA methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(ker, X1, X2, gamma):\n",
    "    K = None\n",
    "    if not ker or ker == 'primal':\n",
    "        K = X1\n",
    "    elif ker == 'linear':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(\n",
    "                np.asarray(X1).T, np.asarray(X2).T)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T)\n",
    "    elif ker == 'rbf':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(\n",
    "                np.asarray(X1).T, np.asarray(X2).T, gamma)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(\n",
    "                np.asarray(X1).T, None, gamma)\n",
    "    return K\n",
    "\n",
    "\n",
    "def proxy_a_distance(source_X, target_X):\n",
    "    \"\"\"\n",
    "    Compute the Proxy-A-Distance of a source/target representation\n",
    "    \"\"\"\n",
    "    nb_source = np.shape(source_X)[0]\n",
    "    nb_target = np.shape(target_X)[0]\n",
    "\n",
    "    train_X = np.vstack((source_X, target_X))\n",
    "    train_Y = np.hstack((np.zeros(nb_source, dtype=int),\n",
    "                         np.ones(nb_target, dtype=int)))\n",
    "\n",
    "    clf = svm.LinearSVC(random_state=0)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    y_pred = clf.predict(train_X)\n",
    "    error = metrics.mean_absolute_error(train_Y, y_pred)\n",
    "    dist = 2 * (1 - 2 * error)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def estimate_mu(_X1, _Y1, _X2, _Y2):\n",
    "    adist_m = proxy_a_distance(_X1, _X2)\n",
    "    C = len(np.unique(_Y1))\n",
    "    epsilon = 1e-3\n",
    "    list_adist_c = []\n",
    "    for i in range(1, C + 1):\n",
    "        ind_i, ind_j = np.where(_Y1 == i), np.where(_Y2 == i)\n",
    "        Xsi = _X1[ind_i[0], :]\n",
    "        Xtj = _X2[ind_j[0], :]\n",
    "        adist_i = proxy_a_distance(Xsi, Xtj)\n",
    "        list_adist_c.append(adist_i)\n",
    "    adist_c = sum(list_adist_c) / C\n",
    "    mu = adist_c / (adist_c + adist_m)\n",
    "    if mu > 1:\n",
    "        mu = 1\n",
    "    if mu < epsilon:\n",
    "        mu = 0\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDA:\n",
    "    def __init__(self, kernel_type='primal', dim=30, lamb=1, mu=0.5, gamma=1, T=10, mode='BDA', estimate_mu=False):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param mu: mu. Default is -1, if not specificied, it calculates using A-distance\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        :param T: iteration number\n",
    "        :param mode: 'BDA' | 'WBDA'\n",
    "        :param estimate_mu: True | False, if you want to automatically estimate mu instead of manally set it\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.mu = mu\n",
    "        self.gamma = gamma\n",
    "        self.T = T\n",
    "        self.mode = mode\n",
    "        self.estimate_mu = estimate_mu\n",
    "\n",
    "    def fit(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform and Predict using 1NN as JDA paper did\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: acc, y_pred, list_acc\n",
    "        '''\n",
    "        #ipdb.set_trace()\n",
    "        list_acc = []\n",
    "        X = np.hstack((Xs.T, Xt.T))  # X.shape: [n_feature, ns+nt]\n",
    "        X /= np.linalg.norm(X, axis=0)  # why it's axis=0?\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        C = len(np.unique(Ys))\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "        mu = self.mu\n",
    "        M = 0\n",
    "        Y_tar_pseudo = None\n",
    "        Xs_new = None\n",
    "        for t in range(self.T):\n",
    "            N = 0\n",
    "            M0 = e * e.T * C\n",
    "            if Y_tar_pseudo is not None and len(Y_tar_pseudo) == nt:\n",
    "                for c in range(1, C + 1):\n",
    "                    e = np.zeros((n, 1))\n",
    "                    Ns = len(Ys[np.where(Ys == c)])\n",
    "                    Nt = len(Y_tar_pseudo[np.where(Y_tar_pseudo == c)])\n",
    "\n",
    "                    if self.mode == 'WBDA':\n",
    "                        Ps = Ns / len(Ys)\n",
    "                        Pt = Nt / len(Y_tar_pseudo)\n",
    "                        alpha = Pt / Ps\n",
    "                        mu = 1\n",
    "                    else:\n",
    "                        alpha = 1\n",
    "\n",
    "                    tt = Ys == c\n",
    "                    e[np.where(tt == True)] = 1 / Ns\n",
    "                    yy = Y_tar_pseudo == c\n",
    "                    ind = np.where(yy == True)\n",
    "                    inds = [item + ns for item in ind]\n",
    "                    e[tuple(inds)] = -alpha / Nt\n",
    "                    e[np.isinf(e)] = 0  # ï¼Ÿ\n",
    "                    N = N + np.dot(e, e.T)\n",
    "\n",
    "            # In BDA, mu can be set or automatically estimated using A-distance\n",
    "            # In WBDA, we find that setting mu=1 is enough\n",
    "            if self.estimate_mu and self.mode == 'BDA':\n",
    "                if Xs_new is not None:\n",
    "                    mu = estimate_mu(Xs_new, Ys, Xt_new, Y_tar_pseudo)\n",
    "                else:\n",
    "                    mu = 0\n",
    "            M = (1 - mu) * M0 + mu * N\n",
    "            M /= np.linalg.norm(M, 'fro')\n",
    "            K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "            n_eye = m if self.kernel_type == 'primal' else n\n",
    "            a, b = np.linalg.multi_dot(\n",
    "                [K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "            w, V = scipy.linalg.eig(a, b)\n",
    "            ind = np.argsort(w)\n",
    "            A = V[:, ind[:self.dim]]\n",
    "            Z = np.dot(A.T, K)\n",
    "            Z /= np.linalg.norm(Z, axis=0)  # why it's axis=0?\n",
    "            Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "            \n",
    "            '''\n",
    "            clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "            clf.fit(Xs_new, Ys.ravel())\n",
    "            Y_tar_pseudo = clf.predict(Xt_new)\n",
    "            acc = sklearn.metrics.accuracy_score(Yt, Y_tar_pseudo)\n",
    "            list_acc.append(acc)\n",
    "            print('{} iteration [{}/{}]: Acc: {:.4f}'.format(self.mode, t + 1, self.T, acc))\n",
    "            '''\n",
    "        return Xs_new, Xt_new, A  #, acc, Y_tar_pseudo, list_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = np.array([np.arange(2+7*i,7+7*i,1) for i in range(4)]).flatten()\n",
    "weekends = np.array([np.arange(7+7*i,9+7*i,1) for i in range(3)]).flatten()[:-1]\n",
    "\n",
    "src_domain = np.array(pd.read_csv('../TCA_traffic/data/siteM4_2168B_20210101_20210131.csv'))[np.array([5,6,7,8]), :]\n",
    "data_target = np.array(pd.read_csv('../TCA_traffic/data/siteM4_2188B_20210101_20210131.csv'))[20:25, :]\n",
    "\n",
    "date_choosen = 10\n",
    "num_test_day = 4\n",
    "#tar_domain = data_target[weekdays[date_choosen:date_choosen+1 + num_test_day], :].reshape(-1, 96)\n",
    "tar_domain = data_target.copy()\n",
    "tgt_validation = tar_domain[1:num_test_day+1, :]\n",
    "\n",
    "Xs = normalize(src_domain.flatten())\n",
    "Xt = normalize(tar_domain.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_seq_len = 1\n",
    "# batch_size = full batch\n",
    "seq_len = 10\n",
    "reduced_dim = 1\n",
    "inp_dim = seq_len\n",
    "label_dim = seq_len\n",
    "hid_dim = 64\n",
    "layers = 3\n",
    "lamb = 3\n",
    "\n",
    "hyper = {\n",
    "    'inp_dim':inp_dim,\n",
    "    'label_dim':label_dim,\n",
    "    'label_seq_len':label_seq_len,\n",
    "    'seq_len':seq_len,\n",
    "    'reduced_dim':reduced_dim,\n",
    "    'hid_dim':hid_dim,\n",
    "    'layers':layers,\n",
    "    'lamb':lamb}\n",
    "hyper = pd.DataFrame(hyper, index=['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inp_dim</th>\n",
       "      <th>label_dim</th>\n",
       "      <th>label_seq_len</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>reduced_dim</th>\n",
       "      <th>hid_dim</th>\n",
       "      <th>layers</th>\n",
       "      <th>lamb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        inp_dim  label_dim  label_seq_len  seq_len  reduced_dim  hid_dim  \\\n",
       "Values       10         10              1       10            1       64   \n",
       "\n",
       "        layers  lamb  \n",
       "Values       3     3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.e. Apply BDA and get $Xs_{new}$, $Xt_{new}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10169\\.conda\\envs\\bda_traff\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\10169\\.conda\\envs\\bda_traff\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "Xs, Ys = sliding_window(Xs, Xs, seq_len, label_seq_len)\n",
    "Xt, Yt = sliding_window(Xt, Xt, seq_len, label_seq_len)\n",
    "\n",
    "inp_dim -= reduced_dim\n",
    "label_dim -= reduced_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374, 9)\n",
      "(96, 9)\n",
      "(374, 9)\n"
     ]
    }
   ],
   "source": [
    "bda = BDA(kernel_type='linear', dim=inp_dim, lamb=lamb, mu=0.9, gamma=1)\n",
    "Xs_new, Xt_new, A = bda.fit(Xs, Ys, Xt, Yt)  # input shape: ns, n_feature | ns, 1\n",
    "Xt_new_valid = Xt_new.copy()[int(96):, :]\n",
    "Xt_new = Xt_new.copy()[:int(96), :]\n",
    "Yt_valid = Yt.copy()[int(96):, :]\n",
    "Yt = Yt.copy()[:int(96), :]\n",
    "\n",
    "print(Xs_new.shape)\n",
    "print(Xt_new.shape)\n",
    "print(Xt_new_valid.shape)\n",
    "\n",
    "np2csv(Xs_new)\n",
    "np2csv(Xt_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a. Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hid_dim, layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(inp_dim, hid_dim, layers, dropout=0.3, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, hid_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim*2, out_dim)\n",
    "        )  # regression\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input: (batchsize, seq_len, input_dim)\n",
    "        # output: (batchsize, seq_len, hid_dim)\n",
    "        #ipdb.set_trace()\n",
    "        y = self.lstm(x)[0]  # y, (h, c) = self.rnn(x)\n",
    "        \n",
    "        y = self.fc(y[:, :, :])  # fully connected layer\n",
    "        \n",
    "        return y[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b. Assemble Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 960\n",
    "\n",
    "train_x = np.vstack([Xs_new, Xt_new])[:, :, np.newaxis]\n",
    "train_y = np.vstack([Ys, Yt])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32).to(device)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32).to(device)\n",
    "Xt_new_valid = torch.tensor(Xt_new_valid[:, :, np.newaxis], dtype=torch.float32).to(device)\n",
    "Yt_valid = torch.tensor(Yt_valid, dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c. Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LSTM(1, 1, hid_dim, layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "#scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No. 0 success, loss: 0.15771, val loss: 0.09857\n",
      "Epoch No. 20 success, loss: 0.05044, val loss: 0.04649\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "net.train()\n",
    "\n",
    "epoches = 1000\n",
    "train_loss_set = []\n",
    "val_loss_set = []\n",
    "\n",
    "for e in range(epoches):\n",
    "    for i in range(len(train_loader)):\n",
    "        try:\n",
    "            data, label = train_iter.next()\n",
    "        except:\n",
    "            train_iter = iter(train_loader)\n",
    "            data, label = train_iter.next()\n",
    "        \n",
    "        out = net(data)\n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        val_out = net(Xt_new_valid)\n",
    "        val_loss = criterion(val_out, Yt_valid)\n",
    "        \n",
    "        val_loss_set.append(val_loss.cpu().detach().numpy())\n",
    "        train_loss_set.append(loss.cpu().detach().numpy())\n",
    "    if e%20==0:\n",
    "        print('Epoch No. %i success, loss: %.5f, val loss: %.5f'%(e, loss.cpu().detach().numpy(), val_loss.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [16, 4])\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(train_loss_set)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(val_loss_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_loss_func(preds, labels):\n",
    "    try:\n",
    "        if preds.device.type == 'cuda':\n",
    "            preds = preds.cpu().detach().numpy()\n",
    "        if labels.device.type == 'cuda':\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "    mask = labels > .05\n",
    "    return np.mean(np.fabs(labels[mask]-preds[mask])/labels[mask])\n",
    "\n",
    "def smape_loss_func(preds, labels):\n",
    "    try:\n",
    "        if preds.device.type == 'cuda':\n",
    "            preds = preds.cpu().detach().numpy()\n",
    "        if labels.device.type == 'cuda':\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "    mask= labels > .05\n",
    "    return np.mean(2*np.fabs(labels[mask]-preds[mask])/(np.fabs(labels[mask])+np.fabs(preds[mask])))\n",
    "\n",
    "def mae_loss_func(preds, labels):\n",
    "    try:\n",
    "        if preds.device.type == 'cuda':\n",
    "            preds = preds.cpu().detach().numpy()\n",
    "        if labels.device.type == 'cuda':\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "    mask= labels > .05\n",
    "    return np.fabs((labels[mask]-preds[mask])).mean()\n",
    "\n",
    "def eliminate_nan(b):\n",
    "    a = np.array(b)\n",
    "    c = a[~np.isnan(a)]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "print('MAPE: %.5f'%mape_loss_func(val_out, Yt_valid))\n",
    "print('SMAPE: %.5f'%smape_loss_func(val_out, Yt_valid))\n",
    "print('MAE: %.5f'%mae_loss_func(val_out, Yt_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda_traff",
   "language": "python",
   "name": "bda_traff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
